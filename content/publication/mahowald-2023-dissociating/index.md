---
title: 'Dissociating language and thought in large language models: a cognitive perspective'
date: '2023-01-01'
publishDate: '2022-09-17T21:47:51.944591Z'
authors:
- Kyle Mahowald
- admin
- Idan A Blank
- Nancy Kanwisher
- Josh Tenenbaum
- Evelina Fedorenko

# Author notes (optional)
author_notes:
  - 'Equal contribution'
  - 'Equal contribution'

publication_types:
- '3'
abstract: 'Today's large language models (LLMs) routinely generate coherent, grammatical and seemingly meaningful paragraphs of text. This achievement has led to speculation that these networks are - or will soon become - "thinking machines", capable of performing tasks that require abstract knowledge and reasoning. Here, we review the capabilities of LLMs by considering their performance on two different aspects of language use: 'formal linguistic competence', which includes knowledge of rules and patterns of a given language, and 'functional linguistic competence', a host of cognitive abilities required for language understanding and use in the real world. Drawing on evidence from cognitive neuroscience, we show that formal competence in humans relies on specialized language processing mechanisms, whereas functional competence recruits multiple extralinguistic capacities that comprise human thought, such as formal reasoning, world knowledge, situation modeling, and social cognition. In line with this distinction, LLMs show impressive (although imperfect) performance on tasks requiring formal linguistic competence, but fail on many tests requiring functional competence. Based on this evidence, we argue that (1) contemporary LLMs should be taken seriously as models of formal linguistic skills; (2) models that master real-life language use would need to incorporate or develop not only a core language module, but also multiple non-language-specific cognitive capacities required for modeling thought. Overall, a distinction between formal and functional linguistic competence helps clarify the discourse surrounding LLMs' potential and provides a path toward building models that understand and use language in human-like ways.'

summary: 'Large language models (LLMs) have come closest among all models to date to mastering human language, yet opinions about their capabilities remain split. Here, we evaluate LLMs using a distinction between formal competence—knowledge of linguistic rules and patterns—and functional competence—understanding and using language in the world. We ground this distinction in human neuroscience, showing that these skills recruit different cognitive mechanisms. Although LLMs are close to mastering formal competence, they still fail at functional competence tasks, which often require drawing on non-linguistic capacities. In short, LLMs are good models of language but incomplete models of human thought.'

featured: true
publication: '*arXiv*'

image:
  caption: 'Language understanding requires not only language-specific, but also general cognitive abilities.'
  focal_point: 'auto'
  preview_only: false

tags:
- LLMs
- review
- position paper

url_pdf: https://arxiv.org/pdf/2301.06627.pdf
doi: https://doi.org/10.48550/arXiv.2301.06627


links:
- name: Tweeprint
  url: https://twitter.com/neuranna/status/1615737072207400962
---
